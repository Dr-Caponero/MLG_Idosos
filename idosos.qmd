---
title: "Caducidade em Idosos"
author: "Camille Menezes, Jeff Caponero e Michel Miler"
format:
    pdf:
      toc: true
      toc-title: Sumário
      colorlinks: true
      documentclass: report
      papersize: letter
      number-sections: false
      geometry:
        - top=30mm
        - left=30mm
        - right=20mm
        - bottom=20mm
        - heightrounded
      fig-pos: "H"
      fig-align: center
      lang: pt-BR
      # fontfamily: libertinus
      fontsize: 12pt
      include-in-header:
      - text: |
          \usepackage{caption}
          \usepackage{fontspec}
          \usepackage{xcolor}
          \usepackage{indentfirst}
          \captionsetup[table]{name=Tabela}
editor: 
  markdown: 
    wrap: 72
---

```{r pacotes&dados}
#| echo: false
#| warning: false

library(pacman)
library(GGally)
pacman::p_load(tidyverse,  readit, summarytools,
               kableExtra,  ggpubr,  gridExtra, 
               glue, corrplot,  readxl, writexl, ggthemes,
               patchwork,  plotly, gglm, ggplot2, tidymodels)

dados <- read_excel("idosos.xlsx")
df <- dados
dados$resp <- as.factor(dados$resp)
dados2 <- NULL
Com <- dados |> filter(resp==1)
Sem <- dados |> filter(resp==0)
```

\newpage

## Introdução

É importante a compreensão das mudanças psicológicas associadas ao envelhecimento. Por isso, este trabalho tem como objetivo analisar um grupo de cinquenta e quatro indivíduos considerados idosos, submetidos a um exame psiquiátrico para avaliar a presença ou ausência de sintomas de caduquice. Acredita-se que os escores obtidos em exames psicológicos prévios podem estar relacionados com a ocorrência desses sintomas. Assim, a presente pesquisa propõe a utilização de um modelo de regressão logística para investigar essa relação.

Os dados são provenientes de (Agresti, 1990, pgs. 122-123). Ao longo deste trabalho, será realizada uma análise descritiva com objetivo de entender um pouco mais as variáveis consideradas, a construção do modelo de regressão com diferentes funções de ligação, a apresentação de resultados inferenciais e estimativas pontuais. Além disso, também será apresentado a análise de resíduos, com foco na identificação de observações atípicas. 


## Análise descritiva

Na amostra de idosos incluídos no estudo, 74% não demonstraram sinais de caduquice. A Tabela 1 apresenta um resumo dos escores registrados por esses idosos.

```{r}
#| echo: false
#| warning: false
#| mensage: false

tab_com <- Com|>
   summarytools::descr(
    stats = c("min", "q1", "med", "mean","q3", "max",  "sd", "cv", "Skewness", "Kurtosis"),
    justify = "c",
    style = "rmarkdown",
    transpose = T)
tab_sem <- Sem|>
   summarytools::descr(
    stats = c("min", "q1", "med", "mean","q3", "max",  "sd", "cv", "Skewness", "Kurtosis"),
    justify = "c",
    style = "rmarkdown",
    transpose = T)

tab <- rbind(tab_com,tab_sem)
rownames(tab) <- c("Com Caducância", "Sem Caducância")
tab|>
    kbl(
    caption = "Estatísticas-resumo para a variável score dos idosos com ou sem caducância",
    digits = 2,
    label = 'tbl-t1' ,
    format.args=list(big.mark=".", decimal.mark=","),
    align = "c", row.names = T, booktabs = T
  )|>
  kable_styling(
    full_width = F, position = 'center', 
    latex_options = c("striped", "HOLD_position", "scale_down", "repeat_header")
  )|>
  column_spec(1, bold = T
              )|>
  kable_material()

```

Na Tabela 1, é possível observar que a média dos scores para os idosos
com caducância é menor do que para os sem caducância. A média e a
mediana para ambos cenários aparentam estar bem próximas entre si, além
da métrica de simetria estar próxima de zero, indicando que a
distribuição dos scores é simétrica para os idosos com ou sem
caducância. Para a curtose, é notável que a distribuição dos scores para
os idosos com caducância é mais platicúrtica que para os idosos sem
caducância.

```{r}
#| echo: false
#| warning: false
#| mensage: false
#| fig-cap: "Boxplot para a variável score dos idosos com ou sem caducância"
#| label: fig-f1
p <- ggplot(dados, aes(x=resp, y=score)) + 
  geom_boxplot()+
  scale_x_discrete(labels=c("Sem caduquice", "Com caduquice"))+
  labs(
    x = "",
    y = "Valor do Score"
  )+
  theme_minimal(base_size = 12)
p

```

Através dos boxplots da @fig-f1, é possível observar que para os idosos
sem caducância, existe uma maior variabilidade dos scores abaixo da
mediana, enquanto que para os scores dos com caducância há uma
variabilidade maior entre a mediana e o terceiro quartil. Tanto pela
Tabela 1 quanto pela @fig-f1, já é possível notar que há uma tendência a
qual menores scores estão mais associados com idosos com caducância.

## Modelo

Queremos analisar como o valor do score obtido no exame psicológico impacta na chance de idoso apresentar caducância ou não. Desse modo, o modelo a ser definido será o modelo MLG binomial com função de ligação logito, então sendo $Y_{i}$ a variável que indica se o idoso "i" apresenta caducância ou não, temos que

* $Y_{i}\sim Binomial(1,\mu_{i})$
* $log(\frac{\mu_{i}}{1-\mu_{i}}) = \alpha + \beta x_{i}$

onde

* $x_{i}$ é a variável score
* $\frac{\mu_{i}}{1-\mu_{i}}$ é a chance
* $\alpha$ é o efeito escalar no logarítmo da chance do idoso apresentar caducância 
* $\beta$ é efeito no logarítmo da chance do idoso apresentar caducância quando uma unidade é adicionada na variável score
* $exp(\beta)$ é efeito na razão da chance do idoso apresentar caducância quando uma unidade é adicionada na variável score
* $\alpha$ é o efeito escalar no logarítmo da chance do idoso apresentar caducância ou não.


Com base nos dados é possível avaliar um modelo de regressão logístico.

```{r}
#| echo: false
#| warning: false

fit_l <- glm(resp~score, data=dados, family = binomial(link="logit"))
tab_l <- summary(fit_l)
tab_l <- tab_l$coefficients
rownames(tab_l) <- c("Intercepto", "Score")
colnames(tab_l) <- c("Estimativa", "EP", "Est. z", "Pr(>|z|)")
parametros_l <- confint(fit_l)

tab_l %>%
  kbl(
    caption = "Resultados para o modelo com função de ligação logito.",
    digits = 4,
    format.args=list(big.mark=".", decimal.mark=","),
    align = "c", 
    row.names = T,
  ) %>%
  kable_styling(
    full_width = F, position = 'center', 
    latex_options = c("striped", "HOLD_position", "repeat_header")
  )|>
  column_spec(1, bold = T
  )|>
  kable_material()
```

```{r }
#| echo: false
#| warning: false

fit_p <- glm(resp~score, data=dados, family = binomial(link="probit"))
tab_p <- summary(fit_p)
tab_p <- tab_p$coefficients
rownames(tab_p) <- c("Intercepto", "Score")
colnames(tab_p) <- c("Estimativa", "EP", "Est. z", "Pr(>|z|)")
parametros_p <- confint(fit_p)
tab_p %>%
  kbl(
    caption = "Resultados para o modelo com função de ligação probito.",
    digits = 4,
    format.args=list(big.mark=".", decimal.mark=","),
    align = "c", 
    row.names = T,
  ) %>%
  kable_styling(
    full_width = F, position = 'center', 
    latex_options = c("striped", "HOLD_position", "repeat_header")
  )|>
  column_spec(1, bold = T
  )|>
  kable_material()
```

```{r}
#| echo: false
#| warning: false

fit_c <- glm(resp~score, data=dados, family = binomial(link="cauchit"))
tab_c <- summary(fit_c)
tab_c <- tab_c$coefficients
rownames(tab_c) <- c("Intercepto", "Score")
colnames(tab_c) <- c("Estimativa", "EP", "Est. z", "Pr(>|z|)")
parametros_c <- confint(fit_c)
tab_c %>%
  kbl(
    caption = "Resultados para o modelo com função de ligação cauchy.",
    digits = 4,
    format.args=list(big.mark=".", decimal.mark=","),
    align = "c", 
    row.names = T,
  ) %>%
  kable_styling(
    full_width = F, position = 'center', 
    latex_options = c("striped", "HOLD_position", "repeat_header")
  )|>
  column_spec(1, bold = T
  )|>
  kable_material()
```

Os modelos apresentados nas Tabelas 2, 3 e 4 são bastante similares. Uma
comparação mais acurada dos modelos pode ser verificada a partir dos
valores de AIC atingidos. A Tabela 5 mostra esses valores.

```{r}
#| echo: false
#| warning: false

aic_l <- summary(fit_l)[5]
aic_p <- summary(fit_p)[5]
aic_c <- summary(fit_c)[5]
aic_l <- as.numeric(aic_l)
aic_p <- as.numeric(aic_p)
aic_c <- as.numeric(aic_c)
aic_l <- round(aic_l,4)
aic_p <- round(aic_p,4)
aic_c <- round(aic_c,4)

tab <- cbind(c("Logito", "Probito", "Cauchy"), c(aic_l,aic_p,aic_c))
colnames(tab) <- c("Função", "AIC")

tab %>%
  kbl(
    caption = "Valores de AIC dos modelos para cada função de ligação.",
    digits = 4,
    format.args=list(big.mark=".", decimal.mark=","),
    align = "c", 
    row.names = F,
  ) %>%
  kable_styling(
    full_width = F, position = 'center', 
    latex_options = c("striped", "HOLD_position", "repeat_header")
  )|>
  column_spec(1, bold = T
  )|>
  kable_material()
```

Desta forma, verifica-se que a diferença entre os modelos é bastante
sutil e não há necessidade de se valer de uma função de ligação
diferente da canônica para explicar os dados. Assim a função de ligação
logito é preferível dentre as demais.

## Resultados Inferenciais

### Estimativas pontuais

Com base no modelo escolhido é possível estimar os valores de $\beta$ e
$\phi$ para o modelo.

```{r}
#| echo: false
#| warning: false

Y <- as.numeric(dados$resp)-1
X <- dados$score
n <- length(Y)
xx <- cbind(1,X)
phi <- n

#chute inicial
alpha <- 1
beta <- 0.1

# inicio das iterações
k <- 0
while(TRUE){
    k <- k+1
    eta <- alpha + beta*X
    mu <- exp(eta)/(1-exp(eta))
    V <- diag((mu)*(1-mu))
    W <- V
    Kbb <- phi*t(xx)%*%W%*%xx
    Kbb_inv <- solve(Kbb)
    z <- eta + solve(V)%*%(Y-mu)
    beta_it <- phi*Kbb_inv%*%t(xx)%*%W%*%z
    if(beta_it[1]-alpha<0.000001 & beta_it[2]-beta<0.000001) break
    alpha <- beta_it[1]
    beta <- beta_it[2]
}
```

Os valores estimados foram de $\alpha =$ `r round(alpha,4)` e de
$\beta_1 =$ `r round(beta,4)`. Com `r k` iterações obteve-se a precisão
de $10^{-6}$.

### Discussão dos resultados

Todos os coeficientes foram significativos ao nível de 5\%. Como a variável score não assume valor zero, o coeficiente do intercepto não apresenta interpretabilidade. A variável score apresenta um coeficiente de -0.3235. Isso indica que, a chance do idoso apresentar caduquice com o aumento de uma unidade na variável score é exp(-0.3235) = 0.7236.


### Função Desvio

O deviance residual é menor do que a deviance nulo 61.806 e 51.017, respectivamente, e também é mais próximo dos graus de liberdade, o que sugere que o modelo com a variável score se ajusta melhor aos dados do que um modelo que não inclui essa variável. Isso indica que a variável score tem algum poder explicativo na variabilidade da caduquice em idosos e contribui para a melhoria do ajuste do modelo.


### Gráficos

Apresente o gráfico da função de distribuição acumulada logística (veja
Aula prática III - dados turbine). Plote o gráfico de $\hat z$ versus
$\hat \eta$ e comente sobre as evidências de adequacidade da função de
ligação.

```{R}
#| echo: false
#| warning: false
#| fig-cap: "Função de distribuição acumulada logística"
#| label: fig-f2

#Kbb
fit <- fit_l
w <- fit$weights
W<-diag(w)
v<-fit$fitted.values*(1-fit$fitted.values)
V<-diag(v)
Kbb<-(t(X)%*%W%*%X)

#Adequacidade da função de ligação
eta <- fit$linear.predictors
z <- eta + (df$resp-fit$fitted.values)/(fit$fitted.values*(1-fit$fitted.values))

ggplot()+
  geom_point(aes(x=eta,y=z))+
  labs(
    x = expression(eta),
    y = "Valor de z"
  )+
  theme_minimal(base_size = 12)
```

### Análise Residual

Considerando os resíduos Studentizado (tsi) padronizado e o componente
do desvio padronizado (tdi) apresente os seguintes gráficos tsi, tdi
versus valores ajustados, tsi , tdi versus valores observados e os
respectivos gráficos do envelope simulado.

```{r }
#| echo: false
#| warning: false
#| fig-cap: "Análise residual. (a) Valores ajustados em função dos resíduos; (b) Valores ajustados em função dos resíduos studentizados."
#| label: fig-f3

X <- model.matrix(fit)
n <- nrow(X)
p <- ncol(X)
w <- fit$weights
W <- diag(w)
H <- solve(t(X)%*%W%*%X)
H <- sqrt(W)%*%X%*%H%*%t(X)%*%sqrt(W)
h <- diag(H)
ts <- resid(fit,type="pearson")/sqrt(1-h)
ts2 <- (ts^2)
td <- resid(fit,type="deviance")/sqrt(1-h)
di <- (h/(1-h))*(ts^2)
tg <- sign(td)*sqrt((1-h)*(td^2)+h*(ts2))
a <- max(td)
b <- min(td)


ggplot() +
  aes(x=fitted(fit), y = td)+
  geom_point()+
  labs(x = "(a) Valores ajustados", y = "Resíduo Componente do Desvio")+
 theme_bw() |
  
ggplot() +
  aes(x=fitted(fit), y = ts)+
  geom_point()+
  labs(x = "(b) Valores ajustados", y = "Resíduo Studentizado")+
  theme_bw() 
```

```{r }
#| echo: false
#| warning: false
#| fig-cap: "Análise residual. (a) Observações em função dos resíduos; (b) Observações em função dos resíduos studentizados."
#| label: fig-f4

obs <- 1:54
ggplot() +
  aes(x = obs, y = td)+
  geom_point()+
  labs(x = "(a) Observações", y = "Resíduo Componente do Desvio")+
  theme_bw() |

ggplot() +
  aes(x = obs, y = ts)+
  geom_point()+
  labs(x = "(b) Observações", y = "Resíduo Studentizado") +
  theme_bw()
```

### Observações Atípicas

Identifique as observações atípicas. Comente cada gráfico.

```{r}
#| echo: false
#| warning: false
#| fig-cap: "Análise de ajuste do modelo. (a) Componentes do desvio; (b) Resíduo de Willians."
#| label: fig-f5

fit.model <- fit
par(mfrow=c(1,2))
X <- model.matrix(fit.model)
n <- nrow(X)
p <- ncol(X)
w <- fit.model$weights
W <- diag(w)
H <- solve(t(X)%*%W%*%X)
H <- sqrt(W)%*%X%*%H%*%t(X)%*%sqrt(W)
h <- diag(H)
td <- resid(fit.model,type="deviance")/sqrt(1-h)
e <- matrix(0,n,100)
#
for(i in 1:100){
  dif <- runif(n) - fitted(fit.model)
  dif[dif >= 0 ] <- 0
  dif[dif<0] <- 1
  nresp <- dif
  fit <- glm(nresp ~ X, family=binomial)
  w <- fit$weights
  W <- diag(w)
  H <- solve(t(X)%*%W%*%X)
  H <- sqrt(W)%*%X%*%H%*%t(X)%*%sqrt(W)
  h <- diag(H)
  e[,i] <- sort(resid(fit,type="deviance")/sqrt(1-h))}
#
e1 <- numeric(n)
e2 <- numeric(n)
#
for(i in 1:n){
  eo <- sort(e[i,])
  e1[i] <- (eo[2]+eo[3])/2
  e2[i] <- (eo[97]+eo[98])/2}
#
med <- apply(e,1,mean)
faixa <- range(td,e1,e2)
par(pty="s")
qqnorm(td,xlab="Percentis da N(0,1)",
       ylab="Componente do Desvio", ylim=faixa, pch=16)
par(new=T)
#
qqnorm(e1,axes=F,xlab="",ylab="",type="l",ylim=faixa,lty=1)
par(new=T)
qqnorm(e2,axes=F,xlab="",ylab="", type="l",ylim=faixa,lty=1)
par(new=T)
qqnorm(med,axes=F,xlab="", ylab="", type="l",ylim=faixa,lty=2)


# Envelope tg

X <- model.matrix(fit.model)
n <- nrow(X)
p <- ncol(X)
w <- fit.model$weights
W <- diag(w)
H <- solve(t(X)%*%W%*%X)
H <- sqrt(W)%*%X%*%H%*%t(X)%*%sqrt(W)
h <- diag(H)
td <- resid(fit.model,type="deviance")/sqrt(1-h)
tg <- sign(td)*sqrt((1-h)*(td^2)+h*(ts^2))
e <- matrix(0,n,100)
#
for(i in 1:100){
  dif <- runif(n) - fitted(fit.model)
  dif[dif >= 0 ] <- 0
  dif[dif<0] <- 1
  nresp <- dif
  fit <- glm(nresp ~ X, family=binomial)
  td <- resid(fit,type="deviance")/sqrt(1-h)
  tg <- sign(td)*sqrt((1-h)*(td^2)+h*(ts^2))
  w <- fit$weights
  W <- diag(w)
  H <- solve(t(X)%*%W%*%X)
  H <- sqrt(W)%*%X%*%H%*%t(X)%*%sqrt(W)
  h <- diag(H)
  e[,i] <- sort(tg)}
#
e1 <- numeric(n)
e2 <- numeric(n)
#
for(i in 1:n){
  eo <- sort(e[i,])
  e1[i] <- (eo[2]+eo[3])/2
  e2[i] <- (eo[97]+eo[98])/2}
#
med <- apply(e,1,mean)
faixa <- range(tg,e1,e2)
par(pty="s")
qqnorm(tg,xlab="Percentis da N(0,1)",
       ylab="Resíduo Williams", ylim=faixa, pch=16)
par(new=T)
#
qqnorm(e1,axes=F,xlab="",ylab="",type="l",ylim=faixa,lty=1)
par(new=T)
qqnorm(e2,axes=F,xlab="",ylab="", type="l",ylim=faixa,lty=1)
par(new=T)
qqnorm(med,axes=F,xlab="", ylab="", type="l",ylim=faixa,lty=2)

```

## Referências

Agresti A. (1990). Categorical Data Analysis. John Wiley, New York.


